{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T13:45:58.241883Z",
     "start_time": "2024-12-26T13:45:58.196798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf  # For image preprocessing and model\n",
    "from IPython.display import Image  # For displaying images in Jupyter\n",
    "import os  # For file path manipulation\n",
    "import tf_keras_vis"
   ],
   "id": "b94feae0503ac098",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T13:37:43.542180Z",
     "start_time": "2024-12-26T13:37:43.529289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ],
   "id": "145d518a36f7750a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-26T13:38:18.762113Z",
     "start_time": "2024-12-26T13:38:18.749976Z"
    }
   },
   "source": [
    "# List of image file paths\n",
    "IMAGE_PATHS = [\"Lenna.png\"]\n",
    "\n",
    "# Indices and layer name for Grad-CAM\n",
    "indices = [263, 281]  # Class indices to visualize (e.g., from ImageNet)\n",
    "layers_name = ['activation_6']  # Layer to focus on for Grad-CAM"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T13:46:56.004149Z",
     "start_time": "2024-12-26T13:46:53.463924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i in range(len(IMAGE_PATHS)):\n",
    "    each_path = IMAGE_PATHS[i]  # Current image path\n",
    "    index = indices[i]  # Target class index\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img = tf.keras.preprocessing.image.load_img(each_path, target_size=(224, 224))  # Resize to 224x224\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)  # Convert to NumPy array\n",
    "    img = tf.expand_dims(img, axis=0)  # Add batch dimension (shape becomes (1, 224, 224, 3))\n",
    "    data = (img, None)  # Prepare data for Grad-CAM\n",
    "\n",
    "    # Define the file name to save the visualization\n",
    "    name = each_path.split(\"/\")[-1].split(\".jpg\")[0]\n",
    "\n",
    "    # Set up Grad-CAM\n",
    "    # explainer = GradCAM()  # Instantiate Grad-CAM\n",
    "    model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)  # Load pre-trained VGG16\n",
    "\n",
    "    # Generate Grad-CAM heatmap\n",
    "    tf_keras_vis.gradcam.GradCAM(model, \"block5_conv3\")\n",
    "    #specified layer and class index\n",
    "\n",
    "    # Save the Grad-CAM visualization\n",
    "    # explainer.save(grid, '.', name + '_grad_cam.png')\n",
    "\n",
    "    # Display the original image and Grad-CAM visualization\n",
    "    # display_images([each_path, name + '_grad_cam.png'])\n"
   ],
   "id": "e6140916fdc470f2",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tf_keras_vis' has no attribute 'gradcam'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 19\u001B[0m\n\u001B[0;32m     16\u001B[0m model \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mapplications\u001B[38;5;241m.\u001B[39mvgg16\u001B[38;5;241m.\u001B[39mVGG16(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m'\u001B[39m, include_top\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# Load pre-trained VGG16\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Generate Grad-CAM heatmap\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m \u001B[43mtf_keras_vis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradcam\u001B[49m\u001B[38;5;241m.\u001B[39mGradCAM(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock5_conv3\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m#specified layer and class index\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Save the Grad-CAM visualization\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# Display the original image and Grad-CAM visualization\u001B[39;00m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# display_images([each_path, name + '_grad_cam.png'])\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tf_keras_vis' has no attribute 'gradcam'"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T13:41:49.506428Z",
     "start_time": "2024-12-26T13:41:49.464235Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "e4e708db90c9cba9",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
